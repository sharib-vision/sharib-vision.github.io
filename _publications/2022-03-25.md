---
title: " FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation"
collection: publications
permalink: /publication/FANet2022_IEEE_TNNLS
excerpt: 'Abstract:
The increase of available large clinical and experimental datasets has contributed to a substantial amount of important contributions in the area of biomedical image analysis. Image segmentation, which is crucial for any quantitative analysis, has especially attracted attention. Recent hardware advancement has led to the success of deep learning approaches. However, although deep learning models are being trained on large datasets, existing methods do not use the information from different learning epochs effectively. In this work, we leverage the information of each training epoch to prune the prediction maps of the subsequent epochs. We propose a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch. The previous epoch mask is then used to provide hard attention to the learned feature maps at different convolutional layers. The network also allows rectifying the predictions in an iterative fashion during the test time. We show that our proposed feedback attention model provides a substantial improvement on most segmentation metrics tested on seven publicly available biomedical imaging datasets demonstrating the effectiveness of FANet. The source code is available at https://github.com/nikhilroxtomar/FANet.'
date: 2022-03-25
venue: 'IEEE Transactions on Neural Networks and Learning Systems'
paperurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9741842'
citation: 'Tomar, N.K., Jha, D., Riegler, M., Johansen, H.D., Johansen, D., Rittscher, J., Halvorsen, P., & Ali, S. (2022). &quot;FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation.&quot; <i>IEEE transactions on neural networks and learning systems</i>.'

---
Abstract:
The increase of available large clinical and experimental datasets has contributed to a substantial amount of important contributions in the area of biomedical image analysis. Image segmentation, which is crucial for any quantitative analysis, has especially attracted attention. Recent hardware advancement has led to the success of deep learning approaches. However, although deep learning models are being trained on large datasets, existing methods do not use the information from different learning epochs effectively. In this work, we leverage the information of each training epoch to prune the prediction maps of the subsequent epochs. We propose a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch. The previous epoch mask is then used to provide hard attention to the learned feature maps at different convolutional layers. The network also allows rectifying the predictions in an iterative fashion during the test time. We show that our proposed feedback attention model provides a substantial improvement on most segmentation metrics tested on seven publicly available biomedical imaging datasets demonstrating the effectiveness of FANet.


Recommended citation: 'Tomar, N.K., Jha, D., Riegler, M., Johansen, H.D., Johansen, D., Rittscher, J., Halvorsen, P., & Ali, S. (2022). &quot;FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation.&quot; <i>IEEE transactions on neural networks and learning systems</i>.'

[[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9741842)][[Code](https://github.com/nikhilroxtomar/FANet)]

<details> <summary>Bibtex</summary>
<br> @ARTICLE{FANet2022,
  author={Tomar, Nikhil Kumar and Jha, Debesh and Riegler, Michael A. and Johansen, Håvard D. and Johansen, Dag and Rittscher, Jens and Halvorsen, Pål and Ali, Sharib},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation}, 
  year={2022},
  volume={},
  number={},
  pages={1-14},
  doi={10.1109/TNNLS.2022.3159394}} </details>
 